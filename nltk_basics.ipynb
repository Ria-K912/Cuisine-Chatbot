{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ff8bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iskit-terra (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iskit-terra (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97949c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98f7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9092d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket = \"After surprising the hosts in the first Test, Sri lanka made a positive start to the second Test as well by bowling  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2103e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_smoke = \"Did you know there was a tower,Where they look out to the land,To see the people quickly passing by\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77238463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tower',\n",
       " ',',\n",
       " 'Where',\n",
       " 'they',\n",
       " 'look',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'land',\n",
       " ',',\n",
       " 'To',\n",
       " 'see',\n",
       " 'the',\n",
       " 'people',\n",
       " 'quickly',\n",
       " 'passing',\n",
       " 'by']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_smoke_token = word_tokenize(black_smoke)\n",
    "black_smoke_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c71a0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you'),\n",
       " ('you', 'know'),\n",
       " ('know', 'there'),\n",
       " ('there', 'was'),\n",
       " ('was', 'a'),\n",
       " ('a', 'tower'),\n",
       " ('tower', ','),\n",
       " (',', 'Where'),\n",
       " ('Where', 'they'),\n",
       " ('they', 'look'),\n",
       " ('look', 'out'),\n",
       " ('out', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'land'),\n",
       " ('land', ','),\n",
       " (',', 'To'),\n",
       " ('To', 'see'),\n",
       " ('see', 'the'),\n",
       " ('the', 'people'),\n",
       " ('people', 'quickly'),\n",
       " ('quickly', 'passing'),\n",
       " ('passing', 'by')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(black_smoke_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d4e01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you', 'know'),\n",
       " ('you', 'know', 'there'),\n",
       " ('know', 'there', 'was'),\n",
       " ('there', 'was', 'a'),\n",
       " ('was', 'a', 'tower'),\n",
       " ('a', 'tower', ','),\n",
       " ('tower', ',', 'Where'),\n",
       " (',', 'Where', 'they'),\n",
       " ('Where', 'they', 'look'),\n",
       " ('they', 'look', 'out'),\n",
       " ('look', 'out', 'to'),\n",
       " ('out', 'to', 'the'),\n",
       " ('to', 'the', 'land'),\n",
       " ('the', 'land', ','),\n",
       " ('land', ',', 'To'),\n",
       " (',', 'To', 'see'),\n",
       " ('To', 'see', 'the'),\n",
       " ('see', 'the', 'people'),\n",
       " ('the', 'people', 'quickly'),\n",
       " ('people', 'quickly', 'passing'),\n",
       " ('quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(black_smoke_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64aacc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you', 'know', 'there'),\n",
       " ('you', 'know', 'there', 'was'),\n",
       " ('know', 'there', 'was', 'a'),\n",
       " ('there', 'was', 'a', 'tower'),\n",
       " ('was', 'a', 'tower', ','),\n",
       " ('a', 'tower', ',', 'Where'),\n",
       " ('tower', ',', 'Where', 'they'),\n",
       " (',', 'Where', 'they', 'look'),\n",
       " ('Where', 'they', 'look', 'out'),\n",
       " ('they', 'look', 'out', 'to'),\n",
       " ('look', 'out', 'to', 'the'),\n",
       " ('out', 'to', 'the', 'land'),\n",
       " ('to', 'the', 'land', ','),\n",
       " ('the', 'land', ',', 'To'),\n",
       " ('land', ',', 'To', 'see'),\n",
       " (',', 'To', 'see', 'the'),\n",
       " ('To', 'see', 'the', 'people'),\n",
       " ('see', 'the', 'people', 'quickly'),\n",
       " ('the', 'people', 'quickly', 'passing'),\n",
       " ('people', 'quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(black_smoke_token,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "977240c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a3f2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('win', 'studi', 'buy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"winning\"), pst.stem(\"studies\"), pst.stem(\"buying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07da5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20ee6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fb78878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8ed855",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_stem = [\"cats\", \"cacti\", \"geese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc64d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats:cat\n",
      "cacti:cactus\n",
      "geese:goose\n"
     ]
    }
   ],
   "source": [
    "for i in words_to_stem:\n",
    "    print(i + \":\" + lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f72324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Error downloading 'abc' from\n",
      "[nltk_data]    |     <https://raw.githubusercontent.com/nltk/nltk_data\n",
      "[nltk_data]    |     /gh-pages/packages/corpora/abc.zip>:   <urlopen\n",
      "[nltk_data]    |     error [WinError 10060] A connection attempt\n",
      "[nltk_data]    |     failed because the connected party did not\n",
      "[nltk_data]    |     properly respond after a period of time, or\n",
      "[nltk_data]    |     established connection failed because connected\n",
      "[nltk_data]    |     host has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b302f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73696204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos\n",
    "peace = \"What do you mean, ' I don't believe in God? I talk to him everyday.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d29cb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "peace_tokenize=word_tokenize(peace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db7c5194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP')]\n",
      "[('do', 'VB')]\n",
      "[('you', 'PRP')]\n",
      "[('mean', 'NN')]\n",
      "[(',', ',')]\n",
      "[(\"'\", \"''\")]\n",
      "[('I', 'PRP')]\n",
      "[('do', 'VB')]\n",
      "[(\"n't\", 'RB')]\n",
      "[('believe', 'VB')]\n",
      "[('in', 'IN')]\n",
      "[('God', 'NNP')]\n",
      "[('?', '.')]\n",
      "[('I', 'PRP')]\n",
      "[('talk', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('him', 'PRP')]\n",
      "[('everyday', 'NN')]\n",
      "[('.', '.')]\n",
      "[(\"'\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "for i in peace_tokenize:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71a4bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mary = \"Mary had a little lamb, who she really loved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d990d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mary_tokenize=word_tokenize(mary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce63a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mary', 'NNP')]\n",
      "[('had', 'VBD')]\n",
      "[('a', 'DT')]\n",
      "[('little', 'JJ')]\n",
      "[('lamb', 'NN')]\n",
      "[(',', ',')]\n",
      "[('who', 'WP')]\n",
      "[('she', 'PRP')]\n",
      "[('really', 'RB')]\n",
      "[('loved', 'VBN')]\n"
     ]
    }
   ],
   "source": [
    "for i in mary_tokenize:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346b9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
